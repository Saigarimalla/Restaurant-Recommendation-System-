{
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "absin7_zomato_bangalore_dataset_path = kagglehub.dataset_download('absin7/zomato-bangalore-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "DrvPJeALsLLw"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "K51zKUNYsLL0"
      },
      "cell_type": "markdown",
      "source": [
        "## How the Restaurant Recommendation System Works?\n",
        "\n",
        "The rapid growth in data collection has led to a new era of a data-driven world. Data is used to create more efficient systems and that’s where recommender systems come in.\n",
        "\n",
        "Recommendation systems are a type of information filtering systems because they improve the quality of search results and provide elements that are more relevant to the search item or that are related to the search history of the user.\n",
        "\n",
        "These are active information filtering systems that personalize the information provided to a user based on their interests, relevance of the information, etc. Recommendation systems are widely used to recommend movies, items, restaurants, places to visit, items to buy, etc.\n",
        "\n",
        "There are two types of recommendation systems:\n",
        "\n",
        "1. Content-based filtering\n",
        "2. Collaborative filtering\n",
        "\n",
        "![](https://i0.wp.com/thecleverprogrammer.com/wp-content/uploads/2020/11/1-recommendation.png?resize=1024%2C627&ssl=1)"
      ]
    },
    {
      "metadata": {
        "id": "raD7-l_zsLL2"
      },
      "cell_type": "markdown",
      "source": [
        "I will start the task of Restaurant Recommendation System by importing the necessary Python Libraries:"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "asc2zxH6sLL3"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DKdWfReosLL4"
      },
      "cell_type": "markdown",
      "source": [
        "Now, I will load and read the dataset:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9Lmlgm7isLL4"
      },
      "cell_type": "code",
      "source": [
        "zomato_real=pd.read_csv(\"../input/zomato-bangalore-dataset/zomato.csv\")\n",
        "zomato_real.head() # prints the first 5 rows of the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GkYG_RWdsLL4"
      },
      "cell_type": "markdown",
      "source": [
        "Now the next step is data cleaning and feature engineering for this step we need to do a lot of stuff with the data such as:\n",
        "\n",
        "1. Deleting Unnecessary Columns\n",
        "2. Removing the Duplicates\n",
        "3. Remove the NaN values from the dataset\n",
        "4. Changing the column names\n",
        "5. Data Transformations\n",
        "6. Data Cleaning\n",
        "7. Adjust the column names\n",
        "Now, let’s perform all the above steps in our data:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "u_AJ6SlLsLL5"
      },
      "cell_type": "code",
      "source": [
        "#Deleting Unnnecessary Columns\n",
        "zomato=zomato_real.drop(['url','dish_liked','phone'],axis=1) #Dropping the column \"dish_liked\", \"phone\", \"url\" and saving the new dataset as \"zomato\"\n",
        "\n",
        "#Removing the Duplicates\n",
        "zomato.duplicated().sum()\n",
        "zomato.drop_duplicates(inplace=True)\n",
        "\n",
        "#Remove the NaN values from the dataset\n",
        "zomato.isnull().sum()\n",
        "zomato.dropna(how='any',inplace=True)\n",
        "\n",
        "#Changing the column names\n",
        "zomato = zomato.rename(columns={'approx_cost(for two people)':'cost','listed_in(type)':'type', 'listed_in(city)':'city'})\n",
        "\n",
        "#Some Transformations\n",
        "zomato['cost'] = zomato['cost'].astype(str) #Changing the cost to string\n",
        "zomato['cost'] = zomato['cost'].apply(lambda x: x.replace(',','.')) #Using lambda function to replace ',' from cost\n",
        "zomato['cost'] = zomato['cost'].astype(float)\n",
        "#Removing '/5' from Rates\n",
        "zomato = zomato.loc[zomato.rate !='NEW']\n",
        "zomato = zomato.loc[zomato.rate !='-'].reset_index(drop=True)\n",
        "remove_slash = lambda x: x.replace('/5', '') if type(x) == np.str else x\n",
        "zomato.rate = zomato.rate.apply(remove_slash).str.strip().astype('float')\n",
        "\n",
        "# Adjust the column names\n",
        "zomato.name = zomato.name.apply(lambda x:x.title())\n",
        "zomato.online_order.replace(('Yes','No'),(True, False),inplace=True)\n",
        "zomato.book_table.replace(('Yes','No'),(True, False),inplace=True)\n",
        "\n",
        "## Computing Mean Rating\n",
        "restaurants = list(zomato['name'].unique())\n",
        "zomato['Mean Rating'] = 0\n",
        "\n",
        "for i in range(len(restaurants)):\n",
        "    zomato['Mean Rating'][zomato['name'] == restaurants[i]] = zomato['rate'][zomato['name'] == restaurants[i]].mean()\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (1,5))\n",
        "zomato[['Mean Rating']] = scaler.fit_transform(zomato[['Mean Rating']]).round(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nOhBjI--sLL5"
      },
      "cell_type": "markdown",
      "source": [
        "Now the next step is to perform some text preprocessing steps which include:\n",
        "\n",
        "1. Lower casing\n",
        "2. Removal of Punctuations\n",
        "3. Removal of Stopwords\n",
        "4. Removal of URLs\n",
        "5. Spelling correction\n",
        "\n",
        "Now let’s perform the above text preprocessing steps on the data:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pCgvwsHYsLL6"
      },
      "cell_type": "code",
      "source": [
        "## Lower Casing\n",
        "zomato[\"reviews_list\"] = zomato[\"reviews_list\"].str.lower()\n",
        "\n",
        "## Removal of Puctuations\n",
        "import string\n",
        "PUNCT_TO_REMOVE = string.punctuation\n",
        "def remove_punctuation(text):\n",
        "    \"\"\"custom function to remove the punctuation\"\"\"\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "\n",
        "zomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_punctuation(text))\n",
        "\n",
        "## Removal of Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "\n",
        "zomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_stopwords(text))\n",
        "\n",
        "## Removal of URLS\n",
        "def remove_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "zomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_urls(text))\n",
        "\n",
        "zomato[['reviews_list', 'cuisines']].sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "WCksCo8CsLL6"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# RESTAURANT NAMES:\n",
        "restaurant_names = list(zomato['name'].unique())\n",
        "def get_top_words(column, top_nu_of_words, nu_of_word):\n",
        "    vec = CountVectorizer(ngram_range= nu_of_word, stop_words='english')\n",
        "    bag_of_words = vec.fit_transform(column)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:top_nu_of_words]\n",
        "\n",
        "zomato=zomato.drop(['address','rest_type', 'type', 'menu_item', 'votes'],axis=1)\n",
        "import pandas\n",
        "\n",
        "# Randomly sample 60% of your dataframe\n",
        "df_percent = zomato.sample(frac=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fAPOCbzGsLL6"
      },
      "cell_type": "markdown",
      "source": [
        "## TF-IDF Vectorization\n",
        "\n",
        "TF-IDF (Term Frequency-Inverse Document Frequency) vectors for each document. This will give you a matrix where each column represents a word in the general vocabulary (all words that appear in at least one document) and each column represents a restaurant, as before.\n",
        "\n",
        "TF-IDF is the statistical method of assessing the meaning of a word in a given document. Now, I will use the TF-IDF vectorization on the dataset:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "EFcL2tk0sLL7"
      },
      "cell_type": "code",
      "source": [
        "df_percent.set_index('name', inplace=True)\n",
        "indices = pd.Series(df_percent.index)\n",
        "\n",
        "# Creating tf-idf matrix\n",
        "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df_percent['reviews_list'])\n",
        "\n",
        "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PAdm1VL6sLL7"
      },
      "cell_type": "markdown",
      "source": [
        "Now the last step for creating a Restaurant Recommendation System is to write a function that will recommend restaurants:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Et9vzx93sLL7"
      },
      "cell_type": "code",
      "source": [
        "def recommend(name, cosine_similarities = cosine_similarities):\n",
        "\n",
        "    # Create a list to put top restaurants\n",
        "    recommend_restaurant = []\n",
        "\n",
        "    # Find the index of the hotel entered\n",
        "    idx = indices[indices == name].index[0]\n",
        "\n",
        "    # Find the restaurants with a similar cosine-sim value and order them from bigges number\n",
        "    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending=False)\n",
        "\n",
        "    # Extract top 30 restaurant indexes with a similar cosine-sim value\n",
        "    top30_indexes = list(score_series.iloc[0:31].index)\n",
        "\n",
        "    # Names of the top 30 restaurants\n",
        "    for each in top30_indexes:\n",
        "        recommend_restaurant.append(list(df_percent.index)[each])\n",
        "\n",
        "    # Creating the new data set to show similar restaurants\n",
        "    df_new = pd.DataFrame(columns=['cuisines', 'Mean Rating', 'cost'])\n",
        "\n",
        "    # Create the top 30 similar restaurants with some of their columns\n",
        "    for each in recommend_restaurant:\n",
        "        df_new = df_new.append(pd.DataFrame(df_percent[['cuisines','Mean Rating', 'cost']][df_percent.index == each].sample()))\n",
        "\n",
        "    # Drop the same named restaurants and sort only the top 10 by the highest rating\n",
        "    df_new = df_new.drop_duplicates(subset=['cuisines','Mean Rating', 'cost'], keep=False)\n",
        "    df_new = df_new.sort_values(by='Mean Rating', ascending=False).head(10)\n",
        "\n",
        "    print('TOP %s RESTAURANTS LIKE %s WITH SIMILAR REVIEWS: ' % (str(len(df_new)), name))\n",
        "\n",
        "    return df_new\n",
        "recommend('Pai Vihar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZTHhj3QsLL7"
      },
      "cell_type": "markdown",
      "source": [
        "#### As as you can see that we got a fairly good output. So, I hope you liked this article on Machine Learning project on Restaurant Recommendation system with Python programming language. Feel free to ask your valuable questions in the comments section"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QmB6_KXbsLL7"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}